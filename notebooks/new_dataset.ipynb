{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b963e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def augment_landmarks(landmarks, augmentation_factor=2):\n",
    "    \"\"\"\n",
    "    –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è landmarks: —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞—Å—Ç—è–∂–µ–Ω–∏–µ –∏ –Ω–µ–±–æ–ª—å—à–æ–µ –≤—Ä–∞—â–µ–Ω–∏–µ\n",
    "    \"\"\"\n",
    "    augmented_samples = []\n",
    "\n",
    "    for _ in range(augmentation_factor):\n",
    "        augmented_landmarks = []\n",
    "\n",
    "        for lm in landmarks:\n",
    "            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é landmark\n",
    "            new_lm = type(\"\", (), {})()  # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –æ–±—ä–µ–∫—Ç\n",
    "            new_lm.x = lm.x\n",
    "            new_lm.y = lm.y\n",
    "            new_lm.z = lm.z\n",
    "\n",
    "            # –°–ª—É—á–∞–π–Ω–æ–µ —Ä–∞—Å—Ç—è–∂–µ–Ω–∏–µ –ø–æ –æ—Å—è–º (–Ω–µ —Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω–æ–µ)\n",
    "            stretch_x = random.uniform(0.95, 1.05)\n",
    "            stretch_y = random.uniform(0.95, 1.05)\n",
    "            stretch_z = random.uniform(0.98, 1.02)  # –ü–æ Z –º–µ–Ω—å—à–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
    "\n",
    "            # –¶–µ–Ω—Ç—Ä –ª–∞–¥–æ–Ω–∏ –¥–ª—è –≤—Ä–∞—â–µ–Ω–∏—è\n",
    "            center_x = np.mean([lm.x for lm in landmarks])\n",
    "            center_y = np.mean([lm.y for lm in landmarks])\n",
    "\n",
    "            # –ù–µ–±–æ–ª—å—à–æ–µ –≤—Ä–∞—â–µ–Ω–∏–µ (–º–∞–∫—Å–∏–º—É–º 15 –≥—Ä–∞–¥—É—Å–æ–≤)\n",
    "            angle = random.uniform(-15, 15) * np.pi / 180  # –í —Ä–∞–¥–∏–∞–Ω–∞—Ö\n",
    "\n",
    "            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–∞—Å—Ç—è–∂–µ–Ω–∏–µ\n",
    "            stretched_x = (new_lm.x - center_x) * stretch_x + center_x\n",
    "            stretched_y = (new_lm.y - center_y) * stretch_y + center_y\n",
    "            stretched_z = new_lm.z * stretch_z\n",
    "\n",
    "            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Ä–∞—â–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤–æ–∫—Ä—É–≥ –æ—Å–∏ Z (–Ω–µ –º–µ–Ω—è–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –∂–µ—Å—Ç–∞)\n",
    "            rotated_x = (\n",
    "                center_x\n",
    "                + (stretched_x - center_x) * np.cos(angle)\n",
    "                - (stretched_y - center_y) * np.sin(angle)\n",
    "            )\n",
    "            rotated_y = (\n",
    "                center_y\n",
    "                + (stretched_x - center_x) * np.sin(angle)\n",
    "                + (stretched_y - center_y) * np.cos(angle)\n",
    "            )\n",
    "\n",
    "            # –ù–µ–±–æ–ª—å—à–æ–µ —Å–ª—É—á–∞–π–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ\n",
    "            offset_x = random.uniform(-0.01, 0.01)\n",
    "            offset_y = random.uniform(-0.01, 0.01)\n",
    "            offset_z = random.uniform(-0.005, 0.005)\n",
    "\n",
    "            # –§–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã\n",
    "            new_lm.x = rotated_x + offset_x\n",
    "            new_lm.y = rotated_y + offset_y\n",
    "            new_lm.z = stretched_z + offset_z\n",
    "\n",
    "            augmented_landmarks.append(new_lm)\n",
    "\n",
    "        augmented_samples.append(augmented_landmarks)\n",
    "\n",
    "    return augmented_samples\n",
    "\n",
    "\n",
    "def extract_features_variations(landmarks):\n",
    "    \"\"\"\n",
    "    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞ –ª–∞–¥–æ–Ω–∏\n",
    "        center_x = np.mean([lm.x for lm in landmarks])\n",
    "        center_y = np.mean([lm.y for lm in landmarks])\n",
    "        center_z = np.mean([lm.z for lm in landmarks])\n",
    "\n",
    "        distances = [\n",
    "            np.linalg.norm([lm.x - center_x, lm.y - center_y, lm.z - center_z])\n",
    "            for lm in landmarks\n",
    "        ]\n",
    "        scale = np.std(distances) if np.std(distances) > 1e-6 else 1e-6\n",
    "\n",
    "        coords = []\n",
    "        for lm in landmarks:\n",
    "            coords.extend(\n",
    "                [\n",
    "                    (lm.x - center_x) / scale,\n",
    "                    (lm.y - center_y) / scale,\n",
    "                    (lm.z - center_z) / scale,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return coords\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error in feature extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_dataset(rows, output_csv, gesture_label):\n",
    "    \"\"\"\n",
    "    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏\n",
    "    \"\"\"\n",
    "    columns = [f\"{axis}{i}\" for i in range(21) for axis in (\"x\", \"y\", \"z\")] + [\n",
    "        \"gesture\",\n",
    "        \"is_right_hand\",\n",
    "    ]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "    metadata = {\n",
    "        \"collection_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"gesture_label\": gesture_label,\n",
    "        \"total_samples\": len(df),\n",
    "        \"right_hand_samples\": len(df[df[\"is_right_hand\"] == 1]),\n",
    "        \"left_hand_samples\": len(df[df[\"is_right_hand\"] == 0]),\n",
    "    }\n",
    "\n",
    "    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø—É—Ç—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "    output_dir = os.path.dirname(output_csv)\n",
    "    if output_dir:  # –ï—Å–ª–∏ –ø—É—Ç—å –Ω–µ –ø—É—Å—Ç–æ–π\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –∏ –¥–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "    if os.path.exists(output_csv):\n",
    "        df_existing = pd.read_csv(output_csv)\n",
    "        df = pd.concat([df_existing, df], ignore_index=True)\n",
    "        print(f\"üìÅ Added to existing dataset. Total samples: {len(df)}\")\n",
    "    else:\n",
    "        print(f\"üìÑ Created new dataset with {len(df)} samples\")\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª\n",
    "    meta_csv = output_csv.replace(\".csv\", \"_metadata.txt\")\n",
    "    with open(meta_csv, \"a\") as f:\n",
    "        f.write(f\"\\n=== Session {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\\n\")\n",
    "        for key, value in metadata.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "\n",
    "def capture_hands_with_augmentation(\n",
    "    output_csv,\n",
    "    gesture_label,\n",
    "    max_samples=100,\n",
    "    augmentation_factor=2,  # –°–∫–æ–ª—å–∫–æ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö samples –¥–æ–±–∞–≤–ª—è—Ç—å –∫ –∫–∞–∂–¥–æ–º—É —Ä–µ–∞–ª—å–Ω–æ–º—É\n",
    "    capture_interval=0.3,\n",
    "):\n",
    "    \"\"\"\n",
    "    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π –∂–µ—Å—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=0.7,\n",
    "        min_tracking_confidence=0.5,\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    count = 0\n",
    "    last_capture_time = 0\n",
    "    augmentation_stats = {\"original\": 0, \"augmented\": 0}\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"!!! Unable to access camera\")\n",
    "        return\n",
    "\n",
    "    print(f\"üé• Capturing: {gesture_label} with augmentation\")\n",
    "    print(f\"üí° Each sample will generate {augmentation_factor} augmented versions\")\n",
    "    print(\"üí° Move your hand around for better data variety!\")\n",
    "\n",
    "    while cap.isOpened() and count < max_samples:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame_flipped = cv2.flip(frame, 1)\n",
    "        image_rgb = cv2.cvtColor(frame_flipped, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(image_rgb)\n",
    "\n",
    "        current_time = time.time()\n",
    "\n",
    "        if (\n",
    "            result.multi_hand_landmarks\n",
    "            and result.multi_handedness\n",
    "            and current_time - last_capture_time >= capture_interval\n",
    "        ):\n",
    "\n",
    "            hand_landmarks = result.multi_hand_landmarks[0]\n",
    "            label = result.multi_handedness[0].classification[0].label\n",
    "            is_right = 1 if label == \"Right\" else 0\n",
    "\n",
    "            # –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô sample\n",
    "            original_coords = extract_features_variations(hand_landmarks.landmark)\n",
    "\n",
    "            if original_coords is not None:\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π sample\n",
    "                rows.append(original_coords + [gesture_label, is_right])\n",
    "                augmentation_stats[\"original\"] += 1\n",
    "                count += 1\n",
    "\n",
    "                print(f\"‚úÖ Sample {count}/{max_samples} | Hand: {label}\")\n",
    "\n",
    "                # –ê–£–ì–ú–ï–ù–¢–ò–†–û–í–ê–ù–ù–´–ï samples\n",
    "                augmented_landmarks_list = augment_landmarks(\n",
    "                    hand_landmarks.landmark, augmentation_factor\n",
    "                )\n",
    "\n",
    "                for i, aug_landmarks in enumerate(augmented_landmarks_list):\n",
    "                    aug_coords = extract_features_variations(aug_landmarks)\n",
    "                    if aug_coords is not None:\n",
    "                        rows.append(aug_coords + [gesture_label, is_right])\n",
    "                        augmentation_stats[\"augmented\"] += 1\n",
    "                        print(f\"   ‚Ü≥ Augmented {i+1}/{augmentation_factor}\")\n",
    "\n",
    "                last_capture_time = current_time\n",
    "\n",
    "            # –†–∏—Å—É–µ–º landmarks\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame_flipped, hand_landmarks, mp_hands.HAND_CONNECTIONS\n",
    "            )\n",
    "\n",
    "        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "        info_text = [\n",
    "            f\"Gesture: {gesture_label}\",\n",
    "            f\"Samples: {count}/{max_samples}\",\n",
    "            f\"Augmented: +{augmentation_stats['augmented']}\",\n",
    "            \"Move hand for variety!\",\n",
    "            \"Press Q to quit\",\n",
    "        ]\n",
    "\n",
    "        for i, text in enumerate(info_text):\n",
    "            cv2.putText(\n",
    "                frame_flipped,\n",
    "                text,\n",
    "                (10, 30 + i * 25),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"Hand Capture - WITH AUGMENTATION\", frame_flipped)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    hands.close()\n",
    "\n",
    "    if rows:\n",
    "        save_dataset(rows, output_csv, gesture_label)\n",
    "        print(f\"üéâ Collection complete!\")\n",
    "        print(\n",
    "            f\"üìä Stats: {augmentation_stats['original']} original + {augmentation_stats['augmented']} augmented = {len(rows)} total samples\"\n",
    "        )\n",
    "\n",
    "        # –ê–Ω–∞–ª–∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "        analyze_collected_data(rows, gesture_label)\n",
    "    else:\n",
    "        print(\"‚ùå No samples captured.\")\n",
    "\n",
    "\n",
    "def visualize_augmentation_example(landmarks, augmented_landmarks):\n",
    "    \"\"\"\n",
    "    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)\n",
    "    \"\"\"\n",
    "    # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "    img = np.zeros((400, 600, 3), dtype=np.uint8)\n",
    "\n",
    "    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –≤ –ø–∏–∫—Å–µ–ª–∏\n",
    "    def to_pixels(x, y):\n",
    "        return int((x + 0.5) * 400), int((y + 0.5) * 400)\n",
    "\n",
    "    # –†–∏—Å—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ landmarks (–∑–µ–ª–µ–Ω—ã–µ)\n",
    "    for i, lm in enumerate(landmarks):\n",
    "        px, py = to_pixels(lm.x, lm.y)\n",
    "        cv2.circle(img, (px, py), 3, (0, 255, 0), -1)\n",
    "        if i < len(landmarks) - 1:\n",
    "            next_px, next_py = to_pixels(landmarks[i + 1].x, landmarks[i + 1].y)\n",
    "            cv2.line(img, (px, py), (next_px, next_py), (0, 255, 0), 1)\n",
    "\n",
    "    # –†–∏—Å—É–µ–º –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ landmarks (–∫—Ä–∞—Å–Ω—ã–µ)\n",
    "    for i, lm in enumerate(augmented_landmarks[0]):  # –ü–µ—Ä–≤—ã–π –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π sample\n",
    "        px, py = to_pixels(lm.x, lm.y)\n",
    "        cv2.circle(img, (px, py), 3, (0, 0, 255), -1)\n",
    "        if i < len(augmented_landmarks[0]) - 1:\n",
    "            next_px, next_py = to_pixels(\n",
    "                augmented_landmarks[0][i + 1].x, augmented_landmarks[0][i + 1].y\n",
    "            )\n",
    "            cv2.line(img, (px, py), (next_px, next_py), (0, 0, 255), 1)\n",
    "\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        \"Green: Original, Red: Augmented\",\n",
    "        (10, 380),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (255, 255, 255),\n",
    "        1,\n",
    "    )\n",
    "    cv2.imshow(\"Augmentation Example\", img)\n",
    "    cv2.waitKey(1000)  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º 1 —Å–µ–∫—É–Ω–¥—É\n",
    "    cv2.destroyWindow(\"Augmentation Example\")\n",
    "\n",
    "\n",
    "def analyze_collected_data(rows, gesture_label):\n",
    "    \"\"\"–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "    print(f\"\\nüìä Analysis for {gesture_label}:\")\n",
    "    print(f\"Total samples: {len(rows)}\")\n",
    "\n",
    "    # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä—É–∫\n",
    "    right_hand_count = sum(1 for row in rows if row[-1] == 1)\n",
    "    left_hand_count = len(rows) - right_hand_count\n",
    "    print(f\"Right hand: {right_hand_count}\")\n",
    "    print(f\"Left hand: {left_hand_count}\")\n",
    "\n",
    "    # –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç\n",
    "    all_coords = [\n",
    "        coord for row in rows for coord in row[:-2]\n",
    "    ]  # –í—Å–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫—Ä–æ–º–µ –º–µ—Ç–æ–∫\n",
    "    print(f\"Coordinate range: [{min(all_coords):.3f}, {max(all_coords):.3f}]\")\n",
    "\n",
    "    if right_hand_count == 0 or left_hand_count == 0:\n",
    "        print(\"‚ö†Ô∏è  Warning: Only one hand type detected. Try using both hands!\")\n",
    "\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Starting hand gesture data collection WITH AUGMENTATION...\")\n",
    "\n",
    "    # –ó–∞—Ö–≤–∞—Ç –¥–∞–Ω–Ω—ã—Ö —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π\n",
    "    capture_hands_with_augmentation(\n",
    "        output_csv=\"don.csv\",\n",
    "        gesture_label=\"don\",\n",
    "        max_samples=300,  # –ú–µ–Ω—å—à–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö samples, –Ω–æ –±–æ–ª—å—à–µ –∑–∞ —Å—á–µ—Ç –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "        augmentation_factor=2,  # 1 –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π + 2 –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö = 3 samples –∑–∞ —Ä–∞–∑\n",
    "        capture_interval=0.1,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

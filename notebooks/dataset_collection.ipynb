{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398a5ccc",
   "metadata": {},
   "source": [
    "### Hand Gesture Data Collection\n",
    "\n",
    "This cell captures hand gesture samples using a webcam and saves them into a CSV file.  \n",
    "The recording pipeline includes:\n",
    "\n",
    "- Real-time hand detection with **MediaPipe Hands**\n",
    "- Normalization of landmarks relative to the wrist\n",
    "- Scaling based on hand size for consistent feature representation\n",
    "- Labeling with:\n",
    "  - gesture name\n",
    "  - left/right hand indicator\n",
    "- Visualization with mirrored preview for user comfort\n",
    "- Configurable:\n",
    "  - number of samples\n",
    "  - capture interval\n",
    "  - camera resolution\n",
    "\n",
    "Each sample contains:\n",
    "\n",
    "- 21 hand landmarks\n",
    "- 3 coordinates per landmark (x, y, z), normalized\n",
    "- gesture label\n",
    "- `is_right_hand` flag (1 = Right, 0 = Left)\n",
    "\n",
    "The collected data is appended to an existing CSV if present, allowing incremental dataset building.\n",
    "\n",
    "**Usage example:**\n",
    "\n",
    "```python\n",
    "capture_hands_to_csv(\n",
    "    output_csv=\"data/gestures.csv\",\n",
    "    gesture_label=\"thumbs_up\",\n",
    "    max_samples=200,\n",
    "    capture_interval=0.2\n",
    ")\n",
    "\n",
    "After running, press q to stop capturing early.\n",
    "\n",
    "The resulting CSV will be used later for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f8d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "def capture_hands_to_csv(\n",
    "    output_csv,\n",
    "    gesture_label,\n",
    "    max_samples=100,\n",
    "    capture_interval=0.1,\n",
    "    frame_width=640,\n",
    "    frame_height=480,\n",
    "):\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    \n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=True,        # process each frame independently\n",
    "        max_num_hands=1,               # capture only one hand\n",
    "        min_detection_confidence=0.9,  # detection confidence threshold\n",
    "        min_tracking_confidence=0.7    # tracking confidence threshold\n",
    "    )\n",
    "\n",
    "    rows = []              # collected samples\n",
    "    count = 0              # number of saved samples\n",
    "    last_capture_time = 0  # time of last saved frame\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # open webcam\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"!!! Unable to access camera\")\n",
    "        return\n",
    "\n",
    "    print(f\"Camera ready. Capturing every {capture_interval}s. Press 'q' to quit.\")\n",
    "\n",
    "    while cap.isOpened() and count < max_samples:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"!!! Can't read frame\")\n",
    "            break\n",
    "\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame_mirrored = cv2.flip(frame, 1)  # mirror for natural user view\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame_mirrored, cv2.COLOR_BGR2RGB)  # convert to RGB\n",
    "        result = hands.process(image_rgb)                             # run hand detection\n",
    "\n",
    "        frame_flipped = cv2.flip(frame, 1)  # display frame (mirrored)\n",
    "\n",
    "        # draw landmarks for user feedback\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                mp.solutions.drawing_utils.draw_landmarks(\n",
    "                    frame_flipped, hand_landmarks, mp_hands.HAND_CONNECTIONS\n",
    "                )\n",
    "\n",
    "        cv2.imshow(\"Hand Capture\", frame_flipped)\n",
    "\n",
    "        label = \"None\"\n",
    "        if result.multi_hand_landmarks and result.multi_handedness:\n",
    "            hand_landmarks = result.multi_hand_landmarks[0]\n",
    "            label = result.multi_handedness[0].classification[0].label\n",
    "            is_right = 1 if label == \"Right\" else 0  # right-hand flag\n",
    "\n",
    "            coords = []\n",
    "            wrist_x = hand_landmarks.landmark[0].x\n",
    "            wrist_y = hand_landmarks.landmark[0].y\n",
    "            wrist_z = hand_landmarks.landmark[0].z\n",
    "\n",
    "            # compute scale based on max distance from wrist\n",
    "            distances = [np.linalg.norm([\n",
    "                lm.x - wrist_x,\n",
    "                lm.y - wrist_y,\n",
    "                lm.z - wrist_z\n",
    "            ]) for lm in hand_landmarks.landmark]\n",
    "            scale = max(distances)\n",
    "\n",
    "            # normalize landmarks\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                x, y, z = lm.x, lm.y, lm.z\n",
    "                x = (x - wrist_x) / scale\n",
    "                y = (y - wrist_y) / scale\n",
    "                z = (z - wrist_z) / scale\n",
    "                coords.extend([x, y, z])\n",
    "\n",
    "            rows.append(coords + [gesture_label, is_right])\n",
    "            count += 1\n",
    "            last_capture_time = time.time()\n",
    "            print(f\"\\t Sample {count}/{max_samples} captured ({label} hand, gesture: {gesture_label})\")\n",
    "\n",
    "        text = f\"{label} hand | Gesture: {gesture_label}\"\n",
    "        cv2.putText(frame_flipped, text, (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Hand Capture\", frame_flipped)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # exit on 'q'\n",
    "            break\n",
    "\n",
    "        # wait until next capture\n",
    "        while time.time() - last_capture_time < capture_interval:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    hands.close()\n",
    "\n",
    "    if not rows:\n",
    "        print(\"No samples recorded.\")\n",
    "        return\n",
    "\n",
    "    # save dataset to CSV\n",
    "    columns = [f\"{axis}{i}\" for i in range(21) for axis in (\"x\", \"y\", \"z\")] + [\"gesture\", \"is_right_hand\"]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "\n",
    "    # append to existing CSV\n",
    "    if os.path.exists(output_csv):\n",
    "        df_existing = pd.read_csv(output_csv)\n",
    "        df = pd.concat([df_existing, df], ignore_index=True)\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nCSV saved: {output_csv} ({len(df)} total rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199cd754",
   "metadata": {},
   "source": [
    "# Collect values for each gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c3c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"question\" \n",
    "output_csv = '../data/raw/upd_question.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f07660",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"if\" \n",
    "output_csv = '../data/raw/upd_if.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444addf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"civilian\" \n",
    "output_csv = '../data/raw/upd_civilian.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"cool\" \n",
    "output_csv = '../data/raw/upd_cool.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"don\" \n",
    "output_csv = '../data/raw/upd_don.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"mafia\" \n",
    "output_csv = '../data/raw/upd_mafia.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"sheriff\" \n",
    "output_csv = '../data/raw/upd_sheriff.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc223ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"you\" \n",
    "output_csv = '../data/raw/upd1_you.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_label=\"me\" \n",
    "output_csv = '../data/raw/upd1_me.csv'\n",
    "\n",
    "capture_hands_to_csv(\n",
    "        output_csv=output_csv,\n",
    "        gesture_label=gesture_label,\n",
    "        max_samples=500,\n",
    "        capture_interval=0.15\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
